# -*- coding: utf-8 -*-
"""P1_Predictive Analytics.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1sAm70E90XN_lFG-_ts6voCTr6SBIpPMa

<h1>Analisis Prediktif : Prediksi Harga Emas di Waktu yang Akan Datang</h1>

##Business Understanding

Problem Statement dan Goals

Metodologi

Metrik

##Data Understanding

Data Loading
"""

# Commented out IPython magic to ensure Python compatibility.
#Import library

#Data Understanding
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
# %matplotlib inline
import seaborn as sns

#Menambah Kredential Kaggle
!pip install kaggle
!mkdir ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

#Menggunduh dataset dari Kaggle
!kaggle datasets download -d sid321axn/gold-price-prediction-dataset

#Mengekstrak File Zip Dataset
!unzip '/content/gold-price-prediction-dataset.zip'

#Load Dataset
golds = pd.read_csv('/content/FINAL_USO.csv', index_col='Date', parse_dates=True, infer_datetime_format=True)
golds.head()

golds.columns

"""Deskripsi Variabel"""

golds.info()

"""<h3>Deskripsi Variabel

"""

golds.describe()

"""Menangani Missing Value"""

#Melihat apakah ada nilai yang kososng
golds.isnull().values.any()

golds.columns = golds.columns.str.lower()

#Mengambil fitur yang berhubungan dengan harga emas
golds_new = golds[['open', 'high', 'low', 'close', 'adj close']]
golds_new.head()

golds_new.columns

golds_new.describe()

#Melihat ukuran data yang akan digunakan
golds_new.shape

#Membuat beberapa fungsi
#fungsi untuk menghitung pengembalian harian
def daily_returns(df: pd.DataFrame, column: str) -> pd.DataFrame:
    df[f'{column}_returns'] = df[column] / df[column].shift(1) - 1
    return df

#fungsi untuk menghitung rata-rata bergerak konvergensi divergensi(MACD)
def calculate_macd(df: pd.DataFrame, column: str, nslow: int = 26, nfast: int = 12) -> pd.DataFrame:
    emaslow = df[column].ewm(span=nslow, min_periods=nslow, adjust=True, ignore_na=False).mean()
    emafast = df[column].ewm(span=nfast, min_periods=nfast, adjust=True, ignore_na=False).mean()
    df[f'dif_{column}'] = emafast - emaslow
    
    df[f'macd_{column}'] = df[f'dif_{column}'].ewm(
        span=9, min_periods=9, adjust=True, ignore_na=False
    ).mean()
    return df

#fungsi untuk menghitung Relative Strangth Index (RSI)
def calculate_rsi(df: pd.DataFrame, column: str, periods: int = 14) -> pd.DataFrame:
    delta = df[column].diff()
    up, down = delta.copy(), delta.copy()
    up[up < 0] = 0
    down[down > 0] = 0

    avg_gain = up.ewm(com=periods, adjust=False).mean()
    avg_loss = down.ewm(com=periods, adjust=False).mean().abs()

    df[f'rsi_{column}'] = 100 - 100 / (1 + avg_gain / avg_loss)
    return df

#fungsi untuk menghitung Simple Moving Average (SMA)
def calculate_sma(df: pd.DataFrame, column: str, periods: int = 15) -> pd.Series:
    sma = df[column].rolling(window=periods, min_periods=periods, center=False).mean()
    return sma

#fungsi untuk menghitung Bollinger Bands
def calculate_bands(df: pd.DataFrame, column: str, peroids: int = 15) -> pd.DataFrame:
    std = df[column].rolling(window=peroids, min_periods=peroids, center=False).std()
    sma = calculate_sma(df, column)
    df[f'upper_band_{column}'] = sma + (2 * std)
    df[f'lower_band_{column}'] = sma - (2 * std)
    return df

#menghitung daily return for gold adjusted close price
target_column = 'adj close'
golds_new = daily_returns(golds_new,target_column)

# Add technical indicators for adjusted gold price
golds_new = calculate_rsi(golds_new, target_column)
golds_new = calculate_bands(golds_new, target_column)
golds_new = calculate_macd(golds_new, target_column)
golds_new.head()

#Melihat data harga emas
plt.plot(golds_new[target_column])
plt.title('Gold Price')
plt.show()

golds_new.columns

#Melihat apakah masih ada data yang kosong
golds_new.isna().sum()

#Melihat apakah ada mata kosong pada data baru yang dibuat
golds_new.isnull().values.any()

#Karena terdapat data kosong pada data baru
#Solusinya dengan membuang data kosong yang ada
golds_new.dropna(inplace=True)

#Melihat apakah masih ada data yang kosong
golds_new.isnull().values.any()

#Melihat apakah masih ada data yang kosong
golds_new.isna().sum()

golds_new.shape

"""Memvisualisasikan Data"""

#Melihat data open
plt.plot(golds_new['open'])
plt.title('open')
plt.show()

#Melihat data high
plt.plot(golds_new['high'])
plt.title('high')
plt.show()

#Melihat data low 
plt.plot(golds_new['low'])
plt.title('low')
plt.show()

#Melihat data close
plt.plot(golds_new['close'])
plt.title('close')
plt.show()

#Melihat data adj close
plt.plot(golds_new['adj close'])
plt.title('adj close')
plt.show()

#Melihat data adj close returns
plt.plot(golds_new['adj close_returns'])
plt.title('adj close_returns')
plt.show()

#Melihat data rsi adj close
plt.plot(golds_new['rsi_adj close'])
plt.title('rsi_adj close')
plt.show()

#Melihat data upper band adj close
plt.plot(golds_new['upper_band_adj close'])
plt.title('upper_band_adj close')
plt.show()

#Melihat data lower band adj close
plt.plot(golds_new['lower_band_adj close'])
plt.title('lower_band_adj close')
plt.show()

#Melihat data dif adj close
plt.plot(golds_new['dif_adj close'])
plt.title('dif_adj close')
plt.show()

#Melihat data macd adj close
plt.plot(golds_new['macd_adj close'])
plt.title('macd_adj close')
plt.show()

"""##Data preparation"""

#Mengelompokkan fitur
feature_column = ['open', 'high', 'low', 'close', 'adj close', 'adj close_returns',
       'rsi_adj close', 'upper_band_adj close', 'lower_band_adj close',
       'dif_adj close', 'macd_adj close']

target_column = 'adj close'

"""Normalisasi"""

from sklearn.preprocessing import MinMaxScaler

scaler = MinMaxScaler()
feature_scaler_data = scaler.fit_transform(golds_new[feature_column])
feature_scaler = pd.DataFrame(columns=feature_column, data=feature_scaler_data, index=golds_new.index)
feature_scaler.head()

"""Pembagian dataset"""

target_column = golds_new[target_column].shift(-1)
val_y = target_column[-90:-1] #mengambil data dari target_column untuk data validasi sebanyak 89 data
target_column = target_column[:-90]

val_x = feature_scaler[-90:-1] #mengambil data dari feature_column untuk data validasi sebanyak 89 data
feature_scaler = feature_scaler[:-90]

from sklearn.model_selection import train_test_split
 
X_train, X_test, y_train, y_test = train_test_split(feature_scaler, target_column, test_size = 0.2, random_state = 123)

X_train.shape

X_test.shape

y_train.shape

y_test.shape

val_x.shape

val_y.shape

"""##Modeling"""

def validate_result(model, model_name):
    predicted = model.predict(val_x)
    RSME_score = np.sqrt(mean_squared_error(val_y, predicted))
    print('RMSE: ', RSME_score)
    
    R2_score = r2_score(val_y, predicted)
    print('R2 score: ', R2_score)

    plt.plot(val_y.index, predicted,'r', label='Predict')
    plt.plot(val_y.index, val_y,'b', label='Actual')
    plt.ylabel('Price')
    plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))
    plt.gca().xaxis.set_major_locator(mdates.MonthLocator())
    plt.title(model_name + ' Predict vs Actual')
    plt.legend(loc='upper right')
    plt.show()

"""Decision Tree"""

from sklearn.tree import DecisionTreeRegressor
from sklearn.metrics import mean_squared_error, r2_score
import matplotlib.dates as mdates
models = {}

model1 = DecisionTreeRegressor(random_state=0)
hist_model1 = model1.fit(X_train, y_train)

validate_result(hist_model1, 'Decision Tree Regression')
models['Decision Tree Regression'] = hist_model1

"""Support Vector Regressor"""

from sklearn.svm import SVR

model2 = SVR(kernel='linear')
hist_model2 = model2.fit(X_train, y_train)
validate_result(hist_model2, 'Linear SVR')
models['SVR'] = hist_model2

#Hyperparameter Tuning
from sklearn.model_selection import GridSearchCV

model2_parameters ={
    'C' :[0.5, 1.0, 10.0, 50.0],
    'epsilon' :[0, 0.1, 0.5, 0.7, 0.9]
}

model2_gridsearch = GridSearchCV(estimator=hist_model2,
                                  param_grid=model2_parameters,)

model2_gridsearch.fit(X_train, y_train)
validate_result(model2_gridsearch, 'Linear SVR GS')
models['SVR with GS'] = model2_gridsearch

"""Random Forest"""

from sklearn.ensemble import RandomForestRegressor

model3 = RandomForestRegressor(n_estimators=50, random_state=0)
hist_model3 = model3.fit(X_train, y_train)
validate_result(hist_model3, 'Random Forest')
models['Random Forest'] = hist_model3

"""LassoCV & RidgeCV"""

from sklearn.linear_model import LassoCV
from sklearn.linear_model import RidgeCV

model4 = LassoCV(n_alphas=1000, max_iter=3000, random_state=0)
model5 = RidgeCV(gcv_mode='auto')

hist_model4 = model4.fit(X_train, y_train)
validate_result(hist_model4,'LassoCV')
models['LassoCV'] = hist_model4

hist_model5 = model5.fit(X_train, y_train)
validate_result(hist_model5,'RidgeCV')
models['RidgeCV'] = hist_model5

"""Gradient Boosting Regressor"""

from sklearn.ensemble import GradientBoostingRegressor
model6 =GradientBoostingRegressor(n_estimators=70, learning_rate=0.1,max_depth=4, random_state=0, loss='ls')
hist_model6 = model6.fit(X_train,y_train)
validate_result(hist_model6,'GB')
models['GB'] = hist_model6

"""Stochastic Gradient Descent"""

from sklearn.linear_model import SGDRegressor
model7 =SGDRegressor(max_iter=1000, tol=1e-3,loss='squared_epsilon_insensitive',penalty='l1',alpha=0.1)
hist_model7 = model7.fit(X_train,y_train)
validate_result(hist_model7,'SGD')
models['SGD'] = hist_model7

"""##Evaluation"""

RMSE_scores = {}
def model_review(models):
    fig, axes = plt.subplots(nrows=3, ncols=3, figsize=(16, 16))

    #plot block
    ax_x = 0
    ax_y = 0
    #plot model
    for name, model in models.items():
        predicted = model.predict(val_x)
        RSME_score = np.sqrt(mean_squared_error(val_y, predicted))

           
        axes[ax_x][ax_y].plot(val_y.index, predicted,'r', label='Predict')
        axes[ax_x][ax_y].plot(val_y.index, val_y,'b', label='Actual')
        axes[ax_x][ax_y].xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))
        axes[ax_x][ax_y].xaxis.set_major_locator(mdates.MonthLocator())
        axes[ax_x][ax_y].set_ylabel('Price')
        axes[ax_x][ax_y].set_title(name + "'s RMSE Error: " +"{0:.2f}".format(RSME_score))
        axes[ax_x][ax_y].legend(loc='upper right')
        RMSE_scores[name] = RSME_score
        if ax_x <=2:
            if ax_y < 2:
                ax_y += 1
            else:
                ax_x += 1
                ax_y = 0
    plt.show()

model_review(models)

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
# %matplotlib inline

model_names = []
model_values = []
for name, value in RMSE_scores.items():
    model_names.append(name)
    model_values.append(value)

model_values = np.array(model_values)
model_names = np.array(model_names)

indices = np.argsort(model_values)
columns = model_names[indices[:8]]
values = model_values[indices][:8]

fig = plt.figure(figsize = (16,8))
plt.bar(columns, values ,width = 0.6, align="center", color = '#ff00c1')
plt.xticks(columns, columns)
plt.xlabel('Model')
plt.ylabel('RMSE')
plt.title('RMSE compare')   
plt.show()

#Hasil dari model yang sudah dibuat
print('Peringkat dari Model yang telah dibuat')
results = [['LassoCV',  0.693, 0.889],
           ['SVR with Hyperparameter',0.697, 0.887], 
           ['RidgeCV', 0.711, 0.883],
           ['Support Vector Regressor',  0.719, 0.880],
           ['Stochastic Gradient Descent', 0.785, 0.857],
           ['Gradient Boosting', 0.786, 0.857],
           ['Random Forest', 0.865, 0.827],
           ['Decision Tree Regression', 1.507, 0.476]]

results_df = pd.DataFrame(results, columns=['Model Type', 'RMSE', 'R2 Score'])
results_df

"""Dari hasil yang didapatkan dari pembuatan beberapa model diatas maka didapatkan nilai RMSE dan R2 Score seperti diatas. Sehingga dapat digunakan model dengan nilai RMSE terendah untuk digunakan sebagai model prediksi harga emas. Model yang mungkin cocok untuk digunakan adalah LassoCV, SVR yang diberikan Hyperparameter Tunning, dan RidgeCV. """